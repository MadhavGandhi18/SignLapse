![github-submission-banner](https://github.com/user-attachments/assets/a1493b84-e4e2-456e-a791-ce35ee2bcf2f)

# 🚀 Project Title

Title: SignLapse

Tagline: Breaking the communication barrier

---

## 📌 Problem Statement

Problem Statement 8 – Reimagine peer to peer learning and mentorship.

Millions of deaf and hard-of-hearing individuals struggle with communication in public and digital spaces.

Sign language interpreters aren't always available.

Real-time accessibility is still missing in many systems.

---

## 🎯 Objective

To create an AI-based solution that converts spoken language to real-time Indian Sign Language using virtual avatars.

Helps bridge the communication gap between hearing and non-hearing individuals.

---

## 🧠 Team & Approach

### Team Name:  
Prodigy

### Team Members:  
- Madhav Gandhi (https://github.com/MadhavGandhi18 / www.linkedin.com/in/madhav-gandhi-478153354 / Team Leader and AI-ML Engineer)  
- Manmeer Singh  
- Krish Singh Nitwal  

Why we chose this problem:
We wanted to make peer learning and mentorship truly inclusive. Millions who use Indian Sign Language are left out of everyday conversations, lectures, and mentor sessions. We saw this gap—and knew tech could bridge it.

Challenges we faced:
Getting avatars to sign in real-time wasn't easy. ISL has unique grammar, and syncing voice to smooth, human-like gestures took a lot of trial and error. We also had limited datasets to work with, which made training and mapping signs a real challenge.

Our turning point:
Midway, we switched from basic video stitching to Unity-based animated avatars—and it changed everything. The output felt alive, expressive, and finally something we were proud to demo.

---

## 🛠️ Tech Stack

### Core Technologies Used:
Blender: Avatar creation and animation.
Python: Backend processing and integration.
OpenCV: For video processing.
MediaPipe: Hand and body pose detection.
Google Text-to-Speech: For spoken word generation.
Speech Recognition API: To convert voice to text
Gemini Api: To translate to regional languages

---

## ✨ Key Features

Highlight the most important features of your project:

✅ Real-time Voice to Sign Conversion
Converts spoken input into Indian Sign Language instantly using expressive animated avatars.

✅ Lifelike Avatar Animations
Our avatars don’t just sign—they move naturally, making communication feel more human and engaging.

✅ Supports Both Live & Pre-recorded Input
Whether it's a live class, a recorded lecture, or a video message—SignLapse can translate it all.

✅ Built for Inclusivity
Designed with a focus on accessibility, this tool helps deaf and hard-of-hearing users fully engage in peer learning and mentorship.

✅ Modular & Scalable
Can be integrated into platforms like Google Meet, Zoom, or educational portals with ease.

✅ Optimized for Indian Sign Language (ISL)
Specifically tailored for ISL, respecting its unique grammar and flow, unlike generic ASL-based tools. 

Add images, GIFs, or screenshots if helpful!

---

## 📽️ Demo & Deliverables

- Demo Video: https://www.youtube.com/watch?v=7f2GxtRaQvI
- Pitch Deck / PPT Link: https://docs.google.com/presentation/d/15z6ZQscn0ZWWEUuOSys46d4hvjj2FuOD/edit?usp=sharing&ouid=106877923158026485472&rtpof=true&sd=true  

---

## ✅ Tasks & Bonus Checklist

- [✅] **All members of the team completed the mandatory task - Followed at least 2 of our social channels and filled the form** (Details in Participant Manual)  
- [✅] **All members of the team completed Bonus Task 1 - Sharing of Badges and filled the form (2 points)**  (Details in Participant Manual)
- [✅] **All members of the team completed Bonus Task 2 - Signing up for Sprint.dev and filled the form (3 points)**  (Details in Participant Manual)

*(Mark with ✅ if completed)*

---

## 🧪 How to Run the Project

### Requirements:
Python 3.8+
Git
ffmpeg (for audio processing)
Google Colab (for model inference if not running locally)
Basic system with GPU (optional but recommended)
Internet connection (for speech-to-text API)

### Local Setup:

# 1. Clone the repo
git clone https://github.com/your-team/signlapse
cd signlapse

# 2. Set up Python environment
python -m venv venv
source venv/bin/activate  # Use venv\Scripts\activate on Windows

# 3. Install dependencies
pip install -r requirements.txt
Make sure to setup next js server files as they are not in repo for security.
Also setup the complete environment for tensorflow for sign language.

# 4. (Optional) Download pre-trained models or datasets
# Place them in the 'models/' and 'data/' folders respectively

# 5. Run the backend script
python main.py

---

## 🧬 Future Scope

We’re just scratching the surface with SignLapse—there’s so much more we’re excited to build:

1. Multilingual Sign Support
Expanding beyond Indian Sign Language to include ASL, BSL, and regional variants, making it a global tool for inclusivity.

2. Real-Time Two-Way Communication
Adding the ability to convert sign language back into text or speech, enabling smoother conversations between deaf and hearing users.

3. Smarter Gesture Prediction
Using more advanced AI to understand context, emotions, and sentence flow for even more natural avatar movements.

4. Mobile & Web Integration
Bringing SignLapse to phones, tablets, and browsers so it’s always accessible—anytime, anywhere.

5. Plug-and-Play for Platforms
Easy integration with platforms like Google Meet, Zoom, and learning management systems to break down communication barriers in real-time.

6. Learning Mode for ISL
A feature to help users actually learn Indian Sign Language using interactive avatars—fun and functional!


---

## 📎 Resources / Credits

Indian Sign Language Dataset (ISL Dataset) – Used for training gesture recognition and sign translation
Google Speech-to-Text API – For converting spoken input into text
MoCap Gesture Datasets – For improving avatar movement realism 

---

## 🏁 Final Words

Building SignLapse wasn’t just about code—it was about connection.

SignLapse started as an idea, but turned into something way more meaningful. We weren’t just building tech—we were building a voice for those often unheard.
From endless bugs to "aha!" moments, this journey was challenging, fun, and deeply fulfilling.
We’re proud of what we created, and even more excited about where it can go next. This is just the beginning.

---
